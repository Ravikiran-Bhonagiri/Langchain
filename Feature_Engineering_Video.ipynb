{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import pandas as pd\n",
    "import re\n",
    "import holidays\n",
    "from textblob import TextBlob\n",
    "import pytesseract\n",
    "import os\n",
    "import cv2\n",
    "from scenedetect import SceneManager, open_video\n",
    "from scenedetect.detectors import ContentDetector\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humor_analyzer = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/dehatebert-mono-english\", device=0)  # Replace with a suitable model\n",
    "whisper_model = whisper.load_model(\"medium\")  # Load Whisper model for audio transcription\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TikTokVideoAnalytics:\n",
    "    def __init__(self, video_path, sound_name, post_timestamp, description, total_interactions, follower_count):\n",
    "        self.video_path = video_path\n",
    "        self.sound_name = sound_name\n",
    "        self.post_timestamp = post_timestamp\n",
    "        self.description = description\n",
    "        self.total_interactions = total_interactions\n",
    "        self.follower_count = follower_count\n",
    "        self.trending_sounds_list = ['Sound1', 'Sound2', 'Sound_ID_or_Name']  # Update with actual trending sounds\n",
    "        self.humor_analyzer = humor_analyzer\n",
    "        self.whisper_model = whisper_model\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "    def get_video_length(self):\n",
    "        \"\"\"Extracts the duration of the video in seconds.\"\"\"\n",
    "        clip = VideoFileClip(self.video_path)\n",
    "        duration = clip.duration\n",
    "        clip.close()\n",
    "        return duration\n",
    "\n",
    "    def is_trending_sound(self):\n",
    "        \"\"\"Checks if a trending sound is used in the video.\"\"\"\n",
    "        return self.sound_name in self.trending_sounds_list\n",
    "\n",
    "    def extract_post_time(self):\n",
    "        \"\"\"\n",
    "        Extracts the day, hour, month, season of posting, checks if the next day is a holiday in the U.S., and checks for long weekends.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert to pandas datetime object\n",
    "            if isinstance(self.post_timestamp, (int, str)) and str(self.post_timestamp).isdigit():\n",
    "                post_time = pd.to_datetime(int(self.post_timestamp), unit='s')\n",
    "            else:\n",
    "                post_time = pd.to_datetime(self.post_timestamp)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing timestamp: {e}\")\n",
    "            return None\n",
    "\n",
    "        day_of_week = post_time.strftime('%A')\n",
    "        hour = post_time.hour\n",
    "        month = post_time.strftime('%B')\n",
    "        month_to_season = {\n",
    "            'January': 'Winter', 'February': 'Winter', 'March': 'Spring',\n",
    "            'April': 'Spring', 'May': 'Spring', 'June': 'Summer',\n",
    "            'July': 'Summer', 'August': 'Summer', 'September': 'Fall',\n",
    "            'October': 'Fall', 'November': 'Fall', 'December': 'Winter'\n",
    "        }\n",
    "        season = month_to_season.get(month, 'Unknown')\n",
    "        us_holidays = holidays.UnitedStates(years=post_time.year)\n",
    "        next_day = post_time + pd.Timedelta(days=1)\n",
    "        next_day_holiday = next_day in us_holidays\n",
    "        next_day_holiday_name = us_holidays.get(next_day) if next_day_holiday else 'None'\n",
    "        is_long_weekend = day_of_week in ['Friday', 'Saturday', 'Sunday', 'Thursday'] and next_day_holiday\n",
    "\n",
    "        return {\n",
    "            'Day': day_of_week,\n",
    "            'Hour': hour,\n",
    "            'Month': month,\n",
    "            'Season': season,\n",
    "            'Next_Day_Holiday': next_day_holiday,\n",
    "            'Next_Day_Holiday_Name': next_day_holiday_name,\n",
    "            'Is_Long_Weekend': is_long_weekend\n",
    "        }\n",
    "\n",
    "    def count_hashtags(self):\n",
    "        \"\"\"Counts the number of hashtags in the video description.\"\"\"\n",
    "        hashtags = re.findall(r'#\\w+', self.description)\n",
    "        return len(hashtags)\n",
    "\n",
    "    def calculate_engagement_rate(self):\n",
    "        \"\"\"Calculates the engagement rate as (total interactions / follower count) * 100.\"\"\"\n",
    "        return (self.total_interactions / self.follower_count) * 100\n",
    "\n",
    "    def analyze_sentiment(self):\n",
    "        \"\"\"Analyzes the sentiment score of the video description.\"\"\"\n",
    "        blob = TextBlob(self.description)\n",
    "        return blob.sentiment.polarity\n",
    "\n",
    "    def is_collaboration(self):\n",
    "        \"\"\"Identifies if the video is a collaboration or duet based on keywords.\"\"\"\n",
    "        keywords = ['duet', 'collaboration', 'with']\n",
    "        return any(keyword in self.description.lower() for keyword in keywords)\n",
    "\n",
    "    def identify_collaboration_type(self):\n",
    "        \"\"\"Identifies the type of collaboration or duet based on keywords.\"\"\"\n",
    "        collab_types = {\n",
    "            'Duet': ['duet'],\n",
    "            'Collaboration': ['collaboration', 'collab'],\n",
    "            'With': ['with']\n",
    "        }\n",
    "        description_lower = self.description.lower()\n",
    "        for collab_type, keywords in collab_types.items():\n",
    "            if any(keyword in description_lower for keyword in keywords):\n",
    "                return collab_type\n",
    "        return 'None'\n",
    "\n",
    "    def is_series(self):\n",
    "        \"\"\"Identifies if the video is part of a series based on general keywords.\"\"\"\n",
    "        series_keywords = ['part', 'episode', 'series', 'sequel', 'continuation']\n",
    "        return any(keyword in self.description.lower() for keyword in series_keywords)\n",
    "\n",
    "    def identify_series_type(self):\n",
    "        \"\"\"Identifies the type of series based on keywords.\"\"\"\n",
    "        series_types = {\n",
    "            'Part Series': ['part 1', 'part 2', 'part 3', 'episode'],\n",
    "            'Sequel': ['sequel', 'continuation', 'follow-up'],\n",
    "            'Multi-Part': ['multi-part', 'series']\n",
    "        }\n",
    "        description_lower = self.description.lower()\n",
    "        for series_type, keywords in series_types.items():\n",
    "            if any(keyword in description_lower for keyword in keywords):\n",
    "                return series_type\n",
    "        return 'None'\n",
    "\n",
    "    def extract_audio_text(self):\n",
    "        \"\"\"Extracts audio from the video and converts it to text using Whisper.\"\"\"\n",
    "        clip = VideoFileClip(self.video_path)\n",
    "        audio_path = \"/notebooks/hackathon/temp_audio.wav\"\n",
    "        clip.audio.write_audiofile(audio_path, codec='pcm_s16le')\n",
    "        clip.close()\n",
    "        result = self.whisper_model.transcribe(audio_path)\n",
    "        return result['text']\n",
    "\n",
    "    def identify_witty_type(self, text):\n",
    "        \"\"\"Analyzes the text to determine the type of wittiness using NLP models.\"\"\"\n",
    "        witty_types = {\n",
    "            'Humor': ['funny', 'joke', 'hilarious', 'comedy'],\n",
    "            'Sarcasm': ['sarcasm', 'irony', 'sarcastic', 'mocking'],\n",
    "            'Clever': ['clever', 'smart', 'witty', 'sharp']\n",
    "        }\n",
    "        text_lower = text.lower()\n",
    "        for witty_type, keywords in witty_types.items():\n",
    "            if any(keyword in text_lower for keyword in keywords):\n",
    "                return witty_type\n",
    "        analysis = self.humor_analyzer(text)\n",
    "        for result in analysis:\n",
    "            if result['label'] in ['Humor', 'Witty', 'Sarcasm']:\n",
    "                return result['label']\n",
    "        return 'None'\n",
    "\n",
    "    def check_wittiness(self, audio_text):\n",
    "        witty_type = self.identify_witty_type(audio_text)\n",
    "        return witty_type\n",
    "\n",
    "    def extract_scene_key_frames(self, output_folder):\n",
    "        # Create a scene manager and add a content detector\n",
    "        video = open_video(self.video_path)\n",
    "        scene_manager = SceneManager()\n",
    "        scene_manager.add_detector(ContentDetector(threshold=30))\n",
    "\n",
    "        # Perform scene detection\n",
    "        scene_manager.detect_scenes(video)\n",
    "        scene_list = scene_manager.get_scene_list()\n",
    "\n",
    "        #print(f\"Detected {len(scene_list)} scenes.\")\n",
    "\n",
    "        # Create output folder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Open the video using OpenCV\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        # List to store paths of saved key frames\n",
    "        key_frames = []\n",
    "\n",
    "        # Extract and save key frames at the start of each detected scene\n",
    "        for i, scene in enumerate(scene_list):\n",
    "            start_frame = scene[0].get_frames()\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if ret:\n",
    "                frame_filename = os.path.join(output_folder, f\"scene_key_frame_{i+1}.jpg\")\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "                key_frames.append(frame_filename)\n",
    "                #print(f\"Saved: {frame_filename}\")\n",
    "\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        return key_frames\n",
    "\n",
    "    def extract_text_from_key_frames(self, frames):\n",
    "        \"\"\"\n",
    "        Extracts text descriptions from key frames using the BLIP model.\n",
    "\n",
    "        Parameters:\n",
    "        - key_frames (list): List of file paths of the key frames.\n",
    "\n",
    "        Returns:\n",
    "        - captions (list): List of extracted text descriptions from the key frames.\n",
    "        \"\"\"\n",
    "        captions = []\n",
    "        for i, frame_path in enumerate(frames):\n",
    "            image = Image.open(frame_path).convert('RGB')\n",
    "            inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model.generate(**inputs)\n",
    "            caption = self.processor.decode(output[0], skip_special_tokens=True)\n",
    "            captions.append(f\"{caption}\")\n",
    "            #print(f\"Caption for Frame {i+1}: {caption}\")\n",
    "\n",
    "        return captions\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Runs the complete pipeline to extract all features including specific types.\"\"\"\n",
    "        # Extract day, hour, month, season, and holiday information\n",
    "        post_time_features = self.extract_post_time()\n",
    "\n",
    "        # Extract key frames from the video\n",
    "        #key_frames = self.extract_scene_key_frames(\"/notebooks/hackathon/dummy\")\n",
    "\n",
    "        # Extract text descriptions from the key frames using BLIP\n",
    "        #captions = self.extract_text_from_key_frames(key_frames)\n",
    "\n",
    "        # Extract transcribed text from the video using Whisper\n",
    "        transcribed_text = self.extract_audio_text()\n",
    "\n",
    "        # Compile all features\n",
    "        features = {\n",
    "            'Video_Length': self.get_video_length(),\n",
    "            'Trending_Sounds': self.is_trending_sound(),\n",
    "            'Post_Day': post_time_features['Day'],\n",
    "            'Post_Hour': post_time_features['Hour'],\n",
    "            'Post_Month': post_time_features['Month'],\n",
    "            'Post_Season': post_time_features['Season'],\n",
    "            'Next_Day_Holiday': post_time_features['Next_Day_Holiday'],\n",
    "            'Next_Day_Holiday_Name': post_time_features['Next_Day_Holiday_Name'],\n",
    "            'Is_Long_Weekend': post_time_features['Is_Long_Weekend'],\n",
    "            'Hashtags': self.count_hashtags(),\n",
    "            'Engagement_Rate': self.calculate_engagement_rate(),\n",
    "            'Sentiment': self.analyze_sentiment(),\n",
    "            'Collaborations': self.is_collaboration(),\n",
    "            'Collaboration_Type': self.identify_collaboration_type(),\n",
    "            'Series': self.is_series(),\n",
    "            'Series_Type': self.identify_series_type(),\n",
    "            'Witty': self.check_wittiness(transcribed_text),\n",
    "            #'Key_Frames': key_frames,  # List of paths to extracted key frames\n",
    "            #'Key_Frame_Captions': captions,  # Captions generated from the key frames\n",
    "            #+'Transcribed_Text': transcribed_text  # Text extracted from the video's audio\n",
    "        }\n",
    "        return features\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
